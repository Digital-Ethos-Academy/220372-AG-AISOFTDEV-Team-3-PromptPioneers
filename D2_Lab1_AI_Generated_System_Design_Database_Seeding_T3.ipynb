{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 15:09:55,322 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/prd_gen.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")\n",
    "\n",
    "adr_content = load_artifact(\"artifacts/adr.md\")\n",
    "if not adr_content:\n",
    "    print(\"Warning: Could not load ard.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQLite Schema ---\n",
      "CREATE TABLE users (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    full_name TEXT,\n",
      "    hashed_password TEXT,\n",
      "    oauth_provider TEXT,\n",
      "    oauth_id TEXT,\n",
      "    role TEXT NOT NULL,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "CREATE TABLE prds (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    status TEXT NOT NULL,\n",
      "    current_version INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_prds_user_id ON prds(user_id);\n",
      "\n",
      "CREATE TABLE prd_versions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    version_number INTEGER NOT NULL,\n",
      "    title TEXT,\n",
      "    description TEXT,\n",
      "    content TEXT,\n",
      "    changelog TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_prd_versions_prd_id ON prd_versions(prd_id);\n",
      "\n",
      "CREATE TABLE problem_statements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    input_text TEXT,\n",
      "    source_type TEXT NOT NULL,\n",
      "    source_url TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_problem_statements_prd_id ON problem_statements(prd_id);\n",
      "\n",
      "CREATE TABLE input_documents (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    filename TEXT NOT NULL,\n",
      "    filetype TEXT NOT NULL,\n",
      "    filesize INTEGER NOT NULL,\n",
      "    content BLOB,\n",
      "    extracted_text TEXT,\n",
      "    uploaded_by INTEGER,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(uploaded_by) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_input_documents_prd_id ON input_documents(prd_id);\n",
      "\n",
      "CREATE TABLE personas (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    name TEXT NOT NULL,\n",
      "    role TEXT,\n",
      "    demographics TEXT,\n",
      "    characteristics TEXT,\n",
      "    description TEXT,\n",
      "    is_ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_personas_prd_id ON personas(prd_id);\n",
      "\n",
      "CREATE TABLE requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    req_type TEXT NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    priority TEXT,\n",
      "    is_implicit INTEGER NOT NULL DEFAULT 0,\n",
      "    status TEXT NOT NULL DEFAULT 'active',\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_requirements_prd_id ON requirements(prd_id);\n",
      "CREATE INDEX idx_requirements_type ON requirements(req_type);\n",
      "\n",
      "CREATE TABLE user_stories (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    persona_id INTEGER,\n",
      "    story_text TEXT NOT NULL,\n",
      "    benefit TEXT,\n",
      "    priority TEXT,\n",
      "    status TEXT NOT NULL DEFAULT 'active',\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(persona_id) REFERENCES personas(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_user_stories_prd_id ON user_stories(prd_id);\n",
      "\n",
      "CREATE TABLE acceptance_criteria (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_story_id INTEGER NOT NULL,\n",
      "    criteria_text TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_story_id) REFERENCES user_stories(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_acceptance_criteria_user_story_id ON acceptance_criteria(user_story_id);\n",
      "\n",
      "CREATE TABLE technical_requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    technology_stack TEXT,\n",
      "    integrations TEXT,\n",
      "    constraints TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_technical_requirements_prd_id ON technical_requirements(prd_id);\n",
      "\n",
      "CREATE TABLE success_metrics (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    goal TEXT NOT NULL,\n",
      "    kpi TEXT NOT NULL,\n",
      "    target_value TEXT,\n",
      "    measurement_method TEXT,\n",
      "    target_timeline TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_success_metrics_prd_id ON success_metrics(prd_id);\n",
      "\n",
      "CREATE TABLE milestones (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    phase TEXT NOT NULL,\n",
      "    deliverables TEXT,\n",
      "    dependencies TEXT,\n",
      "    estimated_date DATETIME,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_milestones_prd_id ON milestones(prd_id);\n",
      "\n",
      "CREATE TABLE chat_sessions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    ended_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_chat_sessions_prd_id ON chat_sessions(prd_id);\n",
      "\n",
      "CREATE TABLE chat_messages (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    session_id INTEGER NOT NULL,\n",
      "    sender_type TEXT NOT NULL,\n",
      "    sender_id INTEGER,\n",
      "    message_text TEXT NOT NULL,\n",
      "    message_type TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(session_id) REFERENCES chat_sessions(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_chat_messages_session_id ON chat_messages(session_id);\n",
      "\n",
      "CREATE TABLE refinement_actions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    action_type TEXT NOT NULL,\n",
      "    entity_type TEXT,\n",
      "    entity_id INTEGER,\n",
      "    change_details TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_refinement_actions_prd_id ON refinement_actions(prd_id);\n",
      "\n",
      "CREATE TABLE export_history (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    export_format TEXT NOT NULL,\n",
      "    exported_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    file_url TEXT,\n",
      "    integration_type TEXT,\n",
      "    integration_status TEXT,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_export_history_prd_id ON export_history(prd_id);\n",
      "\n",
      "CREATE TABLE background_jobs (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER,\n",
      "    job_type TEXT NOT NULL,\n",
      "    status TEXT NOT NULL,\n",
      "    result TEXT,\n",
      "    error_message TEXT,\n",
      "    started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    completed_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_background_jobs_prd_id ON background_jobs(prd_id);\n",
      "\n",
      "CREATE TABLE audit_logs (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER,\n",
      "    prd_id INTEGER,\n",
      "    action TEXT NOT NULL,\n",
      "    details TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);\n",
      "CREATE INDEX idx_audit_logs_prd_id ON audit_logs(prd_id);\n",
      "\n",
      "CREATE TABLE risks (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    risk_type TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    severity TEXT,\n",
      "    mitigation TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_risks_prd_id ON risks(prd_id);\n",
      "\n",
      "CREATE TABLE enhancement_suggestions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    suggestion_text TEXT NOT NULL,\n",
      "    ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    user_selected INTEGER NOT NULL DEFAULT 0,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_enhancement_suggestions_prd_id ON enhancement_suggestions(prd_id);\n",
      "\n",
      "CREATE TABLE clarifying_questions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    question_text TEXT NOT NULL,\n",
      "    ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    answered INTEGER NOT NULL DEFAULT 0,\n",
      "    answer_text TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    answered_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_clarifying_questions_prd_id ON clarifying_questions(prd_id);\n",
      "\n",
      "CREATE TABLE nonfunctional_requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    nfr_category TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_nonfunctional_requirements_prd_id ON nonfunctional_requirements(prd_id);\n",
      "\n",
      "✅ SQLite schema saved to artifacts/schema.sql\n",
      "CREATE TABLE users (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    full_name TEXT,\n",
      "    hashed_password TEXT,\n",
      "    oauth_provider TEXT,\n",
      "    oauth_id TEXT,\n",
      "    role TEXT NOT NULL,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "CREATE TABLE prds (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    status TEXT NOT NULL,\n",
      "    current_version INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_prds_user_id ON prds(user_id);\n",
      "\n",
      "CREATE TABLE prd_versions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    version_number INTEGER NOT NULL,\n",
      "    title TEXT,\n",
      "    description TEXT,\n",
      "    content TEXT,\n",
      "    changelog TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_prd_versions_prd_id ON prd_versions(prd_id);\n",
      "\n",
      "CREATE TABLE problem_statements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    input_text TEXT,\n",
      "    source_type TEXT NOT NULL,\n",
      "    source_url TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_problem_statements_prd_id ON problem_statements(prd_id);\n",
      "\n",
      "CREATE TABLE input_documents (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    filename TEXT NOT NULL,\n",
      "    filetype TEXT NOT NULL,\n",
      "    filesize INTEGER NOT NULL,\n",
      "    content BLOB,\n",
      "    extracted_text TEXT,\n",
      "    uploaded_by INTEGER,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(uploaded_by) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_input_documents_prd_id ON input_documents(prd_id);\n",
      "\n",
      "CREATE TABLE personas (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    name TEXT NOT NULL,\n",
      "    role TEXT,\n",
      "    demographics TEXT,\n",
      "    characteristics TEXT,\n",
      "    description TEXT,\n",
      "    is_ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_personas_prd_id ON personas(prd_id);\n",
      "\n",
      "CREATE TABLE requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    req_type TEXT NOT NULL,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    priority TEXT,\n",
      "    is_implicit INTEGER NOT NULL DEFAULT 0,\n",
      "    status TEXT NOT NULL DEFAULT 'active',\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_requirements_prd_id ON requirements(prd_id);\n",
      "CREATE INDEX idx_requirements_type ON requirements(req_type);\n",
      "\n",
      "CREATE TABLE user_stories (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    persona_id INTEGER,\n",
      "    story_text TEXT NOT NULL,\n",
      "    benefit TEXT,\n",
      "    priority TEXT,\n",
      "    status TEXT NOT NULL DEFAULT 'active',\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(persona_id) REFERENCES personas(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_user_stories_prd_id ON user_stories(prd_id);\n",
      "\n",
      "CREATE TABLE acceptance_criteria (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_story_id INTEGER NOT NULL,\n",
      "    criteria_text TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_story_id) REFERENCES user_stories(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_acceptance_criteria_user_story_id ON acceptance_criteria(user_story_id);\n",
      "\n",
      "CREATE TABLE technical_requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    technology_stack TEXT,\n",
      "    integrations TEXT,\n",
      "    constraints TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_technical_requirements_prd_id ON technical_requirements(prd_id);\n",
      "\n",
      "CREATE TABLE success_metrics (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    goal TEXT NOT NULL,\n",
      "    kpi TEXT NOT NULL,\n",
      "    target_value TEXT,\n",
      "    measurement_method TEXT,\n",
      "    target_timeline TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_success_metrics_prd_id ON success_metrics(prd_id);\n",
      "\n",
      "CREATE TABLE milestones (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    phase TEXT NOT NULL,\n",
      "    deliverables TEXT,\n",
      "    dependencies TEXT,\n",
      "    estimated_date DATETIME,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_milestones_prd_id ON milestones(prd_id);\n",
      "\n",
      "CREATE TABLE chat_sessions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    ended_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_chat_sessions_prd_id ON chat_sessions(prd_id);\n",
      "\n",
      "CREATE TABLE chat_messages (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    session_id INTEGER NOT NULL,\n",
      "    sender_type TEXT NOT NULL,\n",
      "    sender_id INTEGER,\n",
      "    message_text TEXT NOT NULL,\n",
      "    message_type TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(session_id) REFERENCES chat_sessions(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_chat_messages_session_id ON chat_messages(session_id);\n",
      "\n",
      "CREATE TABLE refinement_actions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    action_type TEXT NOT NULL,\n",
      "    entity_type TEXT,\n",
      "    entity_id INTEGER,\n",
      "    change_details TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_refinement_actions_prd_id ON refinement_actions(prd_id);\n",
      "\n",
      "CREATE TABLE export_history (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    user_id INTEGER,\n",
      "    export_format TEXT NOT NULL,\n",
      "    exported_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    file_url TEXT,\n",
      "    integration_type TEXT,\n",
      "    integration_status TEXT,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_export_history_prd_id ON export_history(prd_id);\n",
      "\n",
      "CREATE TABLE background_jobs (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER,\n",
      "    job_type TEXT NOT NULL,\n",
      "    status TEXT NOT NULL,\n",
      "    result TEXT,\n",
      "    error_message TEXT,\n",
      "    started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    completed_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_background_jobs_prd_id ON background_jobs(prd_id);\n",
      "\n",
      "CREATE TABLE audit_logs (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER,\n",
      "    prd_id INTEGER,\n",
      "    action TEXT NOT NULL,\n",
      "    details TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);\n",
      "CREATE INDEX idx_audit_logs_prd_id ON audit_logs(prd_id);\n",
      "\n",
      "CREATE TABLE risks (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    risk_type TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    severity TEXT,\n",
      "    mitigation TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_risks_prd_id ON risks(prd_id);\n",
      "\n",
      "CREATE TABLE enhancement_suggestions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    suggestion_text TEXT NOT NULL,\n",
      "    ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    user_selected INTEGER NOT NULL DEFAULT 0,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_enhancement_suggestions_prd_id ON enhancement_suggestions(prd_id);\n",
      "\n",
      "CREATE TABLE clarifying_questions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    question_text TEXT NOT NULL,\n",
      "    ai_generated INTEGER NOT NULL DEFAULT 1,\n",
      "    answered INTEGER NOT NULL DEFAULT 0,\n",
      "    answer_text TEXT,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    answered_at DATETIME,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_clarifying_questions_prd_id ON clarifying_questions(prd_id);\n",
      "\n",
      "CREATE TABLE nonfunctional_requirements (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    prd_id INTEGER NOT NULL,\n",
      "    nfr_category TEXT NOT NULL,\n",
      "    description TEXT NOT NULL,\n",
      "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY(prd_id) REFERENCES prds(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_nonfunctional_requirements_prd_id ON nonfunctional_requirements(prd_id);\n",
      "\n",
      "✅ SQLite schema saved to artifacts/schema.sql\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate the SQL schema from the PRD.\n",
    "schema_prompt = f\"\"\"\n",
    "You are an experienced Database Administrator (DBA) tasked with designing a normalized SQL schema for an AI-Powered Requirement Analyzer web application built with FastAPI and SQLModel/SQLite architecture.\n",
    "\n",
    "CONTEXT:\n",
    "Below is the complete Product Requirements Document (PRD) that describes the application you need to design a database schema for:\n",
    "\n",
    "{prd_content}\n",
    "\n",
    "ARCHITECTURAL CONSTRAINTS (from ADR-001):\n",
    "- Backend: Single-file FastAPI application in Python\n",
    "- ORM: SQLModel (provides unified ORM and Pydantic-style data validation)\n",
    "- Database: SQLite for zero-configuration persistence and MVP deployment\n",
    "- Background Processing: FastAPI BackgroundTasks for asynchronous AI analysis\n",
    "- Deployment: Single Python file (main.py) for maximum simplicity\n",
    "- Scaling: Designed for lightweight prototype with clear upgrade path to PostgreSQL\n",
    "\n",
    "TASK:\n",
    "Design a normalized SQLite database schema that supports all the functional requirements outlined in the PRD. The schema must be optimized for SQLModel ORM usage and include at least two tables following database normalization best practices.\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Create a normalized schema that eliminates data redundancy and works seamlessly with SQLModel\n",
    "2. Include primary keys, foreign keys, and appropriate indexes optimized for FastAPI/SQLModel queries\n",
    "3. Support all user personas mentioned in the PRD (Startup Founders, Product Managers, Development Team Leads, Consultants)\n",
    "4. Handle the core workflows: problem statement capture, AI analysis, PRD generation, interactive refinement, and export/integration\n",
    "5. Include tables for users, projects/PRDs, requirements, user stories, personas, chat interactions, and version control\n",
    "6. Ensure data types are appropriate for SQLite and SQLModel compatibility\n",
    "7. Include necessary constraints and relationships that support FastAPI's async operations\n",
    "8. Support the non-functional requirements (security, scalability, data privacy) within SQLite limitations\n",
    "9. Design for easy migration to PostgreSQL in future versions\n",
    "\n",
    "KEY ENTITIES TO CONSIDER:\n",
    "- Users (with different roles and OAuth 2.0/SSO authentication support)\n",
    "- Projects/PRDs (with metadata, status, versions, background job tracking)\n",
    "- Problem statements and input documents (with file upload support)\n",
    "- Generated requirements (functional and non-functional)\n",
    "- User stories with acceptance criteria\n",
    "- Identified personas from AI analysis\n",
    "- Chat conversations and refinement interactions (async processing)\n",
    "- Export history and integrations (JSON, PDF, Word formats)\n",
    "- Background job status and results\n",
    "- Audit logs for compliance and debugging\n",
    "\n",
    "SCHEMA DESIGN PRINCIPLES FOR SQLMODEL/FASTAPI:\n",
    "- Use appropriate SQLite data types (TEXT, INTEGER, REAL, BLOB, DATETIME)\n",
    "- Include created_at and updated_at timestamps for all entities\n",
    "- Use INTEGER primary keys for better SQLModel performance (not UUIDs for SQLite)\n",
    "- Implement proper foreign key relationships with CASCADE options\n",
    "- Add indexes for frequently queried columns in API endpoints\n",
    "- Include constraints to ensure data integrity\n",
    "- Consider soft deletes for data retention compliance\n",
    "- Design tables to support FastAPI's automatic request/response models\n",
    "- Optimize for single-file application queries and background task updates\n",
    "- Plan for future PostgreSQL migration (avoid SQLite-specific features where possible)\n",
    "\n",
    "FASTAPI/SQLMODEL SPECIFIC CONSIDERATIONS:\n",
    "- Tables should map cleanly to Pydantic models for API serialization\n",
    "- Include status fields for tracking background AI processing jobs\n",
    "- Design for async query patterns used by FastAPI\n",
    "- Consider JSON columns for flexible metadata storage\n",
    "- Include fields needed for API pagination and filtering\n",
    "- Support file upload metadata and content storage\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide ONLY the raw CREATE TABLE statements in SQLite syntax optimized for SQLModel usage. Do not include explanatory text, comments, or markdown formatting. Ensure proper SQL syntax with semicolons after each statement.\n",
    "\n",
    "Generate a comprehensive schema that supports the full functionality described in the PRD while adhering to the FastAPI + SQLModel + SQLite architectural decisions.\"\"\"\n",
    "\n",
    "print(\"--- Generating SQLite Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "    print(f\"\\n✅ SQLite schema saved to artifacts/schema.sql\")\n",
    "else:\n",
    "    print(\"❌ Skipping schema generation because PRD content is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_schema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO: Write a prompt to generate realistic seed data.\u001b[39;00m\n\u001b[32m      2\u001b[39m seed_data_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mYou are a Database Administrator tasked with creating realistic seed data for an AI-Powered Requirement Analyzer web application. This application helps users convert problem statements into comprehensive Product Requirements Documents (PRDs) using AI analysis.\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33mCONTEXT:\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mBelow is the complete database schema you need to populate with realistic test data:\u001b[39m\n\u001b[32m      7\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcleaned_schema\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33mAPPLICATION CONTEXT (from PRD):\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mprd_content\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33mTASK:\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33mGenerate realistic INSERT statements that populate the database with sample data representing a functioning AI-Powered Requirement Analyzer application. The seed data should demonstrate typical usage scenarios and support testing of all major application features.\u001b[39m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[33mREQUIREMENTS:\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m1. Create data for at least 5-10 realistic users representing different personas (Startup Founders, Product Managers, Development Team Leads, Consultants)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m2. Include 3-5 sample PRD projects in various stages (draft, in-progress, completed)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m3. Generate realistic problem statements, requirements, user stories, and personas for each PRD\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m4. Include sample chat interactions showing AI analysis and user refinement\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m5. Add background job records showing AI processing status\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m6. Include export history and audit logs for realistic application usage\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m7. Ensure all foreign key relationships are properly maintained\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m8. Use realistic names, email addresses, project titles, and technical requirements\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m9. Include timestamps that show realistic project progression over time\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m10. Add sample file uploads and document metadata\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33mDATA GUIDELINES:\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m- Use realistic but fictional user names and email addresses\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m- Create PRD projects for common software applications (mobile apps, web platforms, SaaS tools)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m- Generate meaningful requirement descriptions and user stories\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[33m- Include both functional and non-functional requirements\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[33m- Show realistic AI-generated personas with detailed characteristics\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m- Create chat conversations that demonstrate typical user-AI interactions\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[33m- Include various PRD statuses: draft, analysis_in_progress, ready_for_review, completed\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m- Add realistic job processing states: pending, running, completed, failed\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[33m- Use appropriate priority levels: high, medium, low\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[33m- Include different export formats: JSON, PDF, Word\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[33m- Show integration attempts with external tools\u001b[39m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[33mSAMPLE DATA THEMES:\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[33m- E-commerce mobile app for small businesses\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[33m- Project management SaaS platform\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[33m- Healthcare patient portal\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[33m- Educational learning management system\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[33m- Financial budgeting and tracking tool\u001b[39m\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[33mOUTPUT FORMAT:\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[33mProvide ONLY the raw INSERT statements in SQLite syntax. Do not include explanatory text, comments, or markdown formatting. Ensure proper SQL syntax with semicolons after each statement. Use single quotes for text values and proper date formats (YYYY-MM-DD HH:MM:SS) for DATETIME fields.\u001b[39m\n\u001b[32m     50\u001b[39m \n\u001b[32m     51\u001b[39m \u001b[33mStart with users table, then prds, then related tables in logical dependency order to avoid foreign key constraint violations.\u001b[39m\n\u001b[32m     52\u001b[39m \n\u001b[32m     53\u001b[39m \u001b[33mGenerate comprehensive seed data that demonstrates the full functionality of the AI-Powered Requirement Analyzer application.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Generating Seed Data ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prd_content \u001b[38;5;129;01mand\u001b[39;00m cleaned_schema:\n",
      "\u001b[31mNameError\u001b[39m: name 'cleaned_schema' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n"
     ]
    },
    {
     "ename": "ProviderOperationError",
     "evalue": "[openai:gpt-4.1] completion error: Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    125\u001b[39m exc_map: ExceptionMapping = {socket.timeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\openai\\_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPITimeoutError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\utils\\providers\\openai.py:125\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].text\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m api_error\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover - network dependent\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\utils\\providers\\openai.py:106\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    105\u001b[39m     chat_params[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m] = temperature\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m response = \u001b[43m_call_with_temperature_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_params\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\utils\\providers\\openai.py:70\u001b[39m, in \u001b[36m_call_with_temperature_retry\u001b[39m\u001b[34m(operation, params)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1146\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1256\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\venv\\Lib\\site-packages\\openai\\_base_client.py:1000\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    999\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising timeout error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mAPITimeoutError\u001b[39m: Request timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProviderOperationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Generating Seed Data ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prd_content \u001b[38;5;129;01mand\u001b[39;00m cleaned_schema:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     generated_seed_data = \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_data_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_provider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# Clean up the generated seed data\u001b[39;00m\n\u001b[32m     60\u001b[39m     cleaned_seed_data = clean_llm_output(generated_seed_data, language=\u001b[33m'\u001b[39m\u001b[33msql\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\utils\\llm.py:111\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, client, model_name, api_provider, temperature)\u001b[39m\n\u001b[32m    109\u001b[39m prompt = normalize_prompt(prompt)\n\u001b[32m    110\u001b[39m provider_module = ensure_provider(client, api_provider, model_name, \u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprovider_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Desktop\\220372-AG-AISOFTDEV-Team-3-PromptPioneers\\utils\\providers\\openai.py:127\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m api_error\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover - network dependent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderOperationError(\u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m, model_name, \u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[31mProviderOperationError\u001b[39m: [openai:gpt-4.1] completion error: Request timed out."
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate realistic seed data.\n",
    "cleaned_schema_content = load_artifact(\"artifacts/schema.sql\")\n",
    "if not cleaned_schema_content:\n",
    "    print(\"Warning: Could not load schema. Lab may not function correctly.\")\n",
    "\n",
    "seed_data_prompt = f\"\"\"\n",
    "You are a Database Administrator tasked with creating realistic seed data for an AI-Powered Requirement Analyzer web application. This application helps users convert problem statements into comprehensive Product Requirements Documents (PRDs) using AI analysis.\n",
    "\n",
    "CONTEXT:\n",
    "Below is the complete database schema you need to populate with realistic test data:\n",
    "\n",
    "{cleaned_schema_content}\n",
    "\n",
    "APPLICATION CONTEXT (from PRD):\n",
    "{prd_content}\n",
    "\n",
    "TASK:\n",
    "\n",
    "CONTEXT:\n",
    "Below is the complete database schema you need to populate with realistic test data:\n",
    "\n",
    "{cleaned_schema}\n",
    "\n",
    "APPLICATION CONTEXT (from PRD):\n",
    "{prd_content}\n",
    "\n",
    "TASK:\n",
    "Generate realistic INSERT statements that populate the database with sample data representing a functioning AI-Powered Requirement Analyzer application. The seed data should demonstrate typical usage scenarios and support testing of all major application features.\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Create data for at least 5-10 realistic users representing different personas (Startup Founders, Product Managers, Development Team Leads, Consultants)\n",
    "2. Include 3-5 sample PRD projects in various stages (draft, in-progress, completed)\n",
    "3. Generate realistic problem statements, requirements, user stories, and personas for each PRD\n",
    "4. Include sample chat interactions showing AI analysis and user refinement\n",
    "5. Add background job records showing AI processing status\n",
    "6. Include export history and audit logs for realistic application usage\n",
    "7. Ensure all foreign key relationships are properly maintained\n",
    "8. Use realistic names, email addresses, project titles, and technical requirements\n",
    "9. Include timestamps that show realistic project progression over time\n",
    "10. Add sample file uploads and document metadata\n",
    "\n",
    "DATA GUIDELINES:\n",
    "- Use realistic but fictional user names and email addresses\n",
    "- Create PRD projects for common software applications (mobile apps, web platforms, SaaS tools)\n",
    "- Generate meaningful requirement descriptions and user stories\n",
    "- Include both functional and non-functional requirements\n",
    "- Show realistic AI-generated personas with detailed characteristics\n",
    "- Create chat conversations that demonstrate typical user-AI interactions\n",
    "- Include various PRD statuses: draft, analysis_in_progress, ready_for_review, completed\n",
    "- Add realistic job processing states: pending, running, completed, failed\n",
    "- Use appropriate priority levels: high, medium, low\n",
    "- Include different export formats: JSON, PDF, Word\n",
    "- Show integration attempts with external tools\n",
    "\n",
    "SAMPLE DATA THEMES:\n",
    "- E-commerce mobile app for small businesses\n",
    "- Project management SaaS platform\n",
    "- Healthcare patient portal\n",
    "- Educational learning management system\n",
    "- Financial budgeting and tracking tool\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide ONLY the raw INSERT statements in SQLite syntax. Do not include explanatory text, comments, or markdown formatting. Ensure proper SQL syntax with semicolons after each statement. Use single quotes for text values and proper date formats (YYYY-MM-DD HH:MM:SS) for DATETIME fields.\n",
    "\n",
    "Start with users table, then prds, then related tables in logical dependency order to avoid foreign key constraint violations.\n",
    "\n",
    "Generate comprehensive seed data that demonstrates the full functionality of the AI-Powered Requirement Analyzer application.\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True)\n",
    "    print(f\"\\n✅ Seed data saved to artifacts/seed_data.sql\")\n",
    "else:\n",
    "    print(\"❌ Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Target database path: c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\onboarding1.db\n",
      "📄 Schema file path: c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\schema.sql\n",
      "🌱 Seed file path: c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\seed_data.sql\n",
      "ℹ️  No existing database file found.\n",
      "✅ Successfully connected to database at c:\\Users\\labadmin\\Documents\\AG-AISOFTDEV\\artifacts\\onboarding1.db\n",
      "📖 Reading schema file...\n",
      "🏗️  Creating database tables...\n",
      "✅ Tables created successfully.\n",
      "📊 Loading seed data...\n",
      "🌱 Inserting seed data...\n",
      "✅ Seed data inserted successfully.\n",
      "💾 Database changes committed successfully.\n",
      "📋 Created 7 tables: ['users', 'sqlite_sequence', 'onboarding_templates', 'onboarding_tasks', 'employee_task_progress', 'user_connections', 'onboarding_feedback']\n",
      "🔒 Database connection closed.\n",
      "📋 Created 7 tables: ['users', 'sqlite_sequence', 'onboarding_templates', 'onboarding_tasks', 'employee_task_progress', 'user_connections', 'onboarding_feedback']\n",
      "🔒 Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # TODO: Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"✅ Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # TODO: Read the content of the schema file using load_artifact.\n",
    "        print(\"📖 Reading schema file...\")\n",
    "        schema_sql = load_artifact(\"artifacts/schema.sql\")\n",
    "        if not schema_sql:\n",
    "            print(\"❌ Failed to load schema file\")\n",
    "            return\n",
    "        \n",
    "        # TODO: Execute the schema SQL script.\n",
    "        # Hint: Use cursor.executescript() for multi-statement SQL strings.\n",
    "        print(\"🏗️  Creating database tables...\")\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"✅ Tables created successfully.\")\n",
    "\n",
    "        # TODO: Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            print(\"📊 Loading seed data...\")\n",
    "            seed_sql = load_artifact(\"artifacts/seed_data.sql\")\n",
    "            if seed_sql:\n",
    "                print(\"🌱 Inserting seed data...\")\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"✅ Seed data inserted successfully.\")\n",
    "            else:\n",
    "                print(\"⚠️  Failed to load seed data file\")\n",
    "        else:\n",
    "            print(\"⚠️  Seed data file not found, skipping...\")\n",
    "\n",
    "        # TODO: Commit the changes to the database.\n",
    "        conn.commit()\n",
    "        print(\"💾 Database changes committed successfully.\")\n",
    "        \n",
    "        # Verify the database was created properly\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        print(f\"📋 Created {len(tables)} tables: {[table[0] for table in tables]}\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"❌ Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "    finally:\n",
    "        # TODO: Ensure the connection is closed if it was opened.\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"🔒 Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding1.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "print(f\"🎯 Target database path: {db_file}\")\n",
    "print(f\"📄 Schema file path: {schema_file}\")\n",
    "print(f\"🌱 Seed file path: {seed_file}\")\n",
    "\n",
    "# Clear/delete existing database if it exists\n",
    "if os.path.exists(db_file):\n",
    "    os.remove(db_file)\n",
    "    print(f\"🗑️  Removed existing database file: {db_file}\")\n",
    "else:\n",
    "    print(\"ℹ️  No existing database file found.\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
